{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to your dataset folder\n",
    "dataset_folder = 'archive\\CEDAR\\CEDAR'\n",
    "\n",
    "# Define the percentage of data for the training set\n",
    "train_percentage = 0.7\n",
    "\n",
    "# Initialize lists to store image pairs and their labels\n",
    "train_image_pairs = []\n",
    "train_labels = []\n",
    "test_image_pairs = []\n",
    "test_labels = []\n",
    "\n",
    "# Iterate through each folder in the dataset\n",
    "for folder_name in os.listdir(dataset_folder):\n",
    "    folder_path = os.path.join(dataset_folder, folder_name)\n",
    "\n",
    "    # Create a list of original and forged images in the folder\n",
    "    original_images = []\n",
    "    forged_images = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith('original'):\n",
    "            original_images.append(file_name)\n",
    "        elif file_name.startswith('forgeries'):\n",
    "            forged_images.append(file_name)\n",
    "\n",
    "    # Shuffle the original and forged images to ensure randomness\n",
    "    random.shuffle(original_images)\n",
    "    random.shuffle(forged_images)\n",
    "\n",
    "    # # Determine how many images to use for training and testing based on the percentage\n",
    "    # num_train_original = int(train_percentage * len(original_images))\n",
    "    # num_test_original = len(original_images) - num_train_original\n",
    "    # num_train_forged = int(train_percentage * len(forged_images))\n",
    "    # num_test_forged = len(forged_images) - num_train_forged\n",
    "\n",
    "    # Generate pairs for original-original and original-forged combinations\n",
    "    original_original_pairs = list(combinations(original_images, 2))\n",
    "    original_forged_pairs = [(original_image, forged_image) for original_image in original_images for forged_image in forged_images]\n",
    "\n",
    "    # Shuffle the pairs for randomness\n",
    "    random.shuffle(original_original_pairs)\n",
    "    random.shuffle(original_forged_pairs)\n",
    "\n",
    "    # Select an equal number of original-original and original-forged pairs for training\n",
    "    original_original_pairs = original_original_pairs[:50]\n",
    "    original_forged_pairs = original_forged_pairs[:len(original_original_pairs)]\n",
    "\n",
    "\n",
    "    train_number=int(train_percentage*len(original_original_pairs))\n",
    "\n",
    "    train_original_original_pairs=original_original_pairs[:train_number]\n",
    "    train_original_forged_pairs=original_forged_pairs[:train_number]\n",
    "    # Assign labels (0 for original-original and 1 for original-forged)\n",
    "    train_labels.extend([0] * len(train_original_original_pairs) + [1] * len(train_original_forged_pairs))\n",
    "\n",
    "\n",
    "    # Extend the training sets\n",
    "    train_image_pairs.extend([(os.path.join(folder_path, pair[0]), os.path.join(folder_path, pair[1])) for pair in train_original_original_pairs + train_original_forged_pairs])\n",
    "\n",
    "    # Select the remaining pairs for testing\n",
    "    test_original_original_pairs = original_original_pairs[train_number:]\n",
    "    test_original_forged_pairs = original_forged_pairs[train_number:]\n",
    "\n",
    "    # Assign labels for testing\n",
    "    test_labels.extend([0] * len(test_original_original_pairs) + [1] * len(test_original_forged_pairs))\n",
    "\n",
    "    # Extend the testing sets\n",
    "    test_image_pairs.extend([(os.path.join(folder_path, pair[0]), os.path.join(folder_path, pair[1])) for pair in test_original_original_pairs + test_original_forged_pairs])\n",
    "\n",
    "# Now you have the training and testing sets with image pairs and labels as per your requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample test_image_pairs:\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_2.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_7.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_13.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_16.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_11.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_22.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_14.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_6.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_10.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_22.png') Label: 0\n",
      "Number of test_image_pairs: 1650\n",
      "Number of test_labels: 1650\n",
      "\n",
      "Sample train_image_pairs:\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_3.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_8.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_12.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_21.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_2.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_24.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_24.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_19.png') Label: 0\n",
      "('archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_9.png', 'archive\\\\CEDAR\\\\CEDAR\\\\1\\\\original_1_11.png') Label: 0\n",
      "Number of train_image_pairs: 3850\n",
      "Number of train_labels: 3850\n"
     ]
    }
   ],
   "source": [
    "# Print a few examples from test_image_pairs and test_labels\n",
    "print(\"Sample test_image_pairs:\")\n",
    "for i in range(min(5, len(test_image_pairs))):  # Print up to 5 examples\n",
    "    print(test_image_pairs[i], \"Label:\", test_labels[i])\n",
    "\n",
    "# Print the total number of test_image_pairs and test_labels\n",
    "print(\"Number of test_image_pairs:\", len(test_image_pairs))\n",
    "print(\"Number of test_labels:\", len(test_labels))\n",
    "\n",
    "# Print a few examples from train_image_pairs and train_labels\n",
    "print(\"\\nSample train_image_pairs:\")\n",
    "for i in range(min(5, len(train_image_pairs))):  # Print up to 5 examples\n",
    "    print(train_image_pairs[i], \"Label:\", train_labels[i])\n",
    "\n",
    "# Print the total number of train_image_pairs and train_labels\n",
    "print(\"Number of train_image_pairs:\", len(train_image_pairs))\n",
    "print(\"Number of train_labels:\", len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "241/241 [==============================] - 692s 3s/step - loss: 0.2687 - accuracy: 0.8618 - val_loss: 0.1295 - val_accuracy: 0.9491\n",
      "Epoch 2/10\n",
      "241/241 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9886Reached target accuracy of 0.95. Stopping training.\n",
      "241/241 [==============================] - 785s 3s/step - loss: 0.0439 - accuracy: 0.9886 - val_loss: 0.0573 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a function to preprocess the image pairs\n",
    "def preprocess_image(image_path):\n",
    "    # Load, resize, and normalize the image\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = keras.preprocessing.image.img_to_array(image) / 255.0\n",
    "    return image\n",
    "\n",
    "# Define the Siamese CNN model\n",
    "def create_siamese_model(input_shape):\n",
    "    # Define the base network (subnetwork)\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu')(input_layer)\n",
    "    x = keras.layers.MaxPooling2D()(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "    base_network = keras.models.Model(input_layer, x)\n",
    "\n",
    "    # Create the left and right inputs\n",
    "    input_left = keras.layers.Input(shape=input_shape)\n",
    "    input_right = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Generate the embeddings for the left and right inputs\n",
    "    embedding_left = base_network(input_left)\n",
    "    embedding_right = base_network(input_right)\n",
    "\n",
    "    # Calculate the L1 distance between the embeddings\n",
    "    L1_distance = keras.layers.Lambda(lambda embeddings: tf.abs(embeddings[0] - embeddings[1]))([embedding_left, embedding_right])\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = keras.layers.Dense(1, activation='sigmoid')(L1_distance)\n",
    "\n",
    "    # Create the Siamese model\n",
    "    siamese_model = keras.models.Model(inputs=[input_left, input_right], outputs=output_layer)\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "# Create and compile the Siamese model\n",
    "input_shape = (224, 224, 3)\n",
    "siamese_model = create_siamese_model(input_shape)\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert your image pairs to NumPy arrays\n",
    "train_image_pairs_left = np.array([preprocess_image(pair[0]) for pair in train_image_pairs])\n",
    "train_image_pairs_right = np.array([preprocess_image(pair[1]) for pair in train_image_pairs])\n",
    "\n",
    "# Convert your labels to a NumPy array\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Similarly, preprocess and convert test image pairs and labels\n",
    "test_image_pairs_left = np.array([preprocess_image(pair[0]) for pair in test_image_pairs])\n",
    "test_image_pairs_right = np.array([preprocess_image(pair[1]) for pair in test_image_pairs])\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class CustomEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='val_accuracy', target_accuracy=0.95):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.target_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get(self.monitor)\n",
    "        if current_accuracy is not None and current_accuracy >= self.target_accuracy:\n",
    "            print(f\"Reached target accuracy of {self.target_accuracy}. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "custom_early_stopping = CustomEarlyStopping(target_accuracy=0.95)\n",
    "\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_accuracy', patience=1, restore_best_weights=True)\n",
    "\n",
    "# siamese_model.fit(\n",
    "#     [train_image_pairs_left, train_image_pairs_right],\n",
    "#     train_labels,\n",
    "#     batch_size=8,\n",
    "#     epochs=10,\n",
    "#     validation_data=([test_image_pairs_left, test_image_pairs_right], test_labels)\n",
    "# )\n",
    "\n",
    "siamese_model.fit(\n",
    "    [train_image_pairs_left, train_image_pairs_right],\n",
    "    train_labels,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    validation_data=([test_image_pairs_left, test_image_pairs_right], test_labels),\n",
    "    callbacks=[custom_early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "siamese_model.save('final')\n",
    "\n",
    "\n",
    "\n",
    "# You can then use the test predictions to calculate the percentage of similarity between signature pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 43s 809ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_predictions = siamese_model.predict(\n",
    "    [test_image_pairs_left,test_image_pairs_right]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.9615384615384616\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9803921568627451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_predictions are probabilities or class labels and test_labels are the true labels\n",
    "# If test_predictions are probabilities, you can convert them to class labels using a threshold\n",
    "threshold = 0.5  # You can adjust the threshold based on your specific problem\n",
    "predicted_labels = (test_predictions > threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels)\n",
    "recall = recall_score(test_labels, predicted_labels)\n",
    "f1 = f1_score(test_labels, predicted_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00049728], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your two test images\n",
    "\n",
    "# image1=preprocess_image('forgeries_1_1.png')\n",
    "# image2=preprocess_image('original_1_1.png')\n",
    "# image3=preprocess_image('original_1_3.png')\n",
    "\n",
    "\n",
    "image1 = np.array([preprocess_image('forgeries_13_20.png') ])\n",
    "image2 = np.array([preprocess_image('forgeries_13_24.png') ])\n",
    "image3 = np.array([preprocess_image('original_13_7.png') ])\n",
    "image4 = np.array([preprocess_image('original_13_16.png') ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n",
      "[[0.00138519]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions1= siamese_model.predict([image1,image2])\n",
    "print(test_predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions1= siamese_model.predict([image3,image2])\n",
    "print(test_predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "[[0.06186659]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions1= siamese_model.predict([image3,image4])\n",
    "print(test_predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions1= siamese_model.predict([image2,image4])\n",
    "print(test_predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
